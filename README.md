{::options parse_block_html="true" /}
<div style="float: right">
![portrait](./assets/images/personal-portrait-small-150px.jpeg)

{:refdef: style="text-align: center;"}
[![email](./assets/images/email.png)](mailto:sammie.katt@gmail.com)
[![linked-in](./assets/images/linked-in-logo.png)](https://www.linkedin.com/in/sammie-katt-6a82a095/)
[![github](./assets/images/github-mark.png)](https://www.github.com/sammiekatt)
{: refdef}

</div>

I am a postdoctoral researcher at Aalto University working with [Sami Kaski](https://kaski-lab.com/) on human-AI collaboration.
Before that, I did my PhD at Northeastern University with [Chris Amato](https://www.ccs.neu.edu/home/camato/), after I had finished my master's at the University of Amsterdam supervised by [ Frans Oliehoek ](https://www.fransoliehoek.net/wp/).
During my master's and Phd, I worked on **Bayesian reinforcement learning**.
Since then, I have focused on **human-AI collaboration**.
Here, I  focus on designing AI that model their users as *intentional* agents with *beliefs over the consequences of their interactions with the system*. 

You can find a taste of my research [here](/research), though for a comprehensive list look at [google scholar](https://scholar.google.com/citations?&user=NZmmHacAAAAJ).
Where apropriate, I have included the code repositories there. For all my public code, check out my [github](https://www.github.com/sammiekatt) instead.

Core ideas behind my work are:

- **Computational Rationality and Theory of Mind** (Bounded): the theory that human behavior can be explained as decision making that optimize some utility, albeit limited by constraints. This theory provides a principled and general approach for modeling, inferring, and predicting actions from humans.
- **Theory of Mind**: this concept is crucial to our ability to collaborate. By assigning *beliefs*, *desires*, and *intentions* to each other, we model each other with incredible accuracy. This, in turn, 
- **Bayesian Inference & Uncertainty Estimation**: I am particular interested in problems where it is not obvious what the best solution is and --- when we are not --- how to deal with this uncertainty. This uncertainty can be with respect to the state of the environments, its dynamics, or the task. The Bayesian prospective provides a j

My work is an attempt at using these concepts to develop systems that infer intentions, predict actions, and understand user goals in order to collaborate.
Applications and problem settings of particular interest, to me, have been "human-in-the-loop" settings.
This is a broad class of problems defined by the fact that a *user* is a key part of the problem and includes, for example, AI for science and reinforcement learning from human feedback.

# News

- Jan 2026: our work "[More Than Irrational: Modeling Belief-Biased Agents](https://research.aalto.fi/en/publications/more-than-irrational-modeling-belief-biased-agents/)" got accepted at AAAI (congrats [Yifan](https://yifan-zhu.com)!). I will also present a poster at AAAI workshop [ToM4AI](https://tom4ai.github.io/events/AAAI2026/) on "Theory of Mind in Human-in-the-Loop".
- Dec 2025: the site is live!
